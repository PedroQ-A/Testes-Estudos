# Product Requirements Document (PRD)
# FlowForge Dashboard com Integra√ß√£o LLM

**Vers√£o:** 2.0.0  
**Data:** 2025-09-12  
**Status:** Para Aprova√ß√£o  
**Abordagem:** H√≠brida (LLM Local + Cloud)  
**Revis√£o:** Enhanced with comprehensive sections

---

## üìã Sum√°rio Executivo

### Vis√£o do Produto
O **FlowForge Dashboard com Integra√ß√£o LLM** √© uma plataforma de visualiza√ß√£o gerencial que permite aos gestores monitorar em tempo real a produtividade de suas equipes atrav√©s de conversas naturais com intelig√™ncia artificial. O sistema combina o poder de LLMs locais (custo zero) com LLMs cloud (an√°lises complexas) para fornecer insights profundos sobre performance, gargalos e oportunidades de melhoria.

### Problema a Resolver
- **Visibilidade limitada**: Gestores n√£o t√™m vis√£o consolidada do trabalho da equipe
- **An√°lise manual**: Horas gastas criando relat√≥rios e analisando dados
- **Insights perdidos**: Padr√µes e anomalias n√£o detectados em tempo h√°bil
- **Custo de LLM**: APIs cloud caras para queries simples e repetitivas

### Solu√ß√£o Proposta
Dashboard interativo com interface conversacional que permite queries em linguagem natural, gerando automaticamente visualiza√ß√µes e insights atrav√©s de uma arquitetura h√≠brida que otimiza custos (70% de redu√ß√£o) mantendo alta qualidade de resposta.

### Benef√≠cios Principais
- **Economia de 60-70%** nos custos de LLM atrav√©s de processamento h√≠brido
- **Respostas em <500ms** para queries locais, <3s para cloud
- **Interface conversacional** em portugu√™s com suporte a voz
- **Visualiza√ß√µes autom√°ticas** baseadas no contexto da pergunta
- **Insights proativos** com detec√ß√£o de anomalias e previs√µes

---

## üéØ Objetivos e Metas

### Objetivos Prim√°rios
1. **Visibilidade Total**: Dashboard unificado com m√©tricas em tempo real
2. **An√°lise por IA**: Queries em linguagem natural gerando insights autom√°ticos
3. **Redu√ß√£o de Custos**: Minimizar gastos com APIs de LLM atrav√©s de arquitetura h√≠brida
4. **Produtividade**: Eliminar gera√ß√£o manual de relat√≥rios (economia de 10h/semana)
5. **Decis√µes Data-Driven**: Insights acion√°veis baseados em dados reais

### Metas SMART
- **Q1 2025**: MVP funcional com 5 tipos de queries pr√©-definidas
- **Q2 2025**: Integra√ß√£o h√≠brida completa (local + cloud) com 60% economia
- **Q3 2025**: Fine-tuning com dados reais, 90% accuracy em queries espec√≠ficas
- **Q4 2025**: 100% ado√ß√£o pela equipe, ROI positivo demonstrado

### KPIs de Sucesso
| M√©trica | Meta | Medi√ß√£o |
|---------|------|---------|
| **Tempo de Resposta** | <500ms local, <3s cloud | p95 latency |
| **Redu√ß√£o de Custos** | 60-70% vs cloud-only | Custo mensal de API |
| **Satisfa√ß√£o do Usu√°rio** | >4.5/5 | NPS trimestral |
| **Queries Processadas** | >1000/dia | Analytics dashboard |
| **Uptime** | 99.9% | Monitoring tools |
| **Adoption Rate** | 100% em 3 meses | Active users |

---

## üìö Gloss√°rio T√©cnico

### Termos de IA/LLM
- **LLM (Large Language Model)**: Modelo de linguagem grande treinado para processar e gerar texto
- **RAG (Retrieval-Augmented Generation)**: T√©cnica que combina recupera√ß√£o de informa√ß√µes com gera√ß√£o
- **Embedding**: Representa√ß√£o vetorial de texto para compara√ß√£o sem√¢ntica
- **Fine-tuning**: Ajuste de modelo pr√©-treinado com dados espec√≠ficos
- **Hallucination**: Resposta incorreta ou inventada pelo LLM
- **Token**: Unidade b√°sica de texto processada pelo LLM
- **Prompt Injection**: Ataque que manipula entrada para obter resposta indesejada
- **Vector Store**: Banco de dados especializado em busca por similaridade
- **Semantic Cache**: Cache baseado em significado, n√£o em texto exato

### Termos Arquiteturais
- **API Gateway**: Ponto √∫nico de entrada para requisi√ß√µes da API
- **Load Balancer**: Distribuidor de carga entre m√∫ltiplos servidores
- **Circuit Breaker**: Padr√£o que previne cascata de falhas
- **Blue-Green Deploy**: Estrat√©gia de implanta√ß√£o sem downtime
- **Horizontal Scaling**: Adi√ß√£o de mais servidores para aumentar capacidade
- **Microservices**: Arquitetura de pequenos servi√ßos independentes
- **Event Sourcing**: Padr√£o que armazena mudan√ßas como eventos
- **CQRS**: Separa√ß√£o de comandos (write) e consultas (read)

### Termos de Neg√≥cio
- **ROI (Return on Investment)**: Retorno sobre investimento
- **NPS (Net Promoter Score)**: M√©trica de satisfa√ß√£o do cliente
- **KPI (Key Performance Indicator)**: Indicador-chave de performance
- **SLA (Service Level Agreement)**: Acordo de n√≠vel de servi√ßo
- **TCO (Total Cost of Ownership)**: Custo total de propriedade
- **MVP (Minimum Viable Product)**: Produto m√≠nimo vi√°vel
- **POC (Proof of Concept)**: Prova de conceito
- **TTM (Time to Market)**: Tempo para chegar ao mercado

---

## üó∫Ô∏è Jornada do Usu√°rio e Fluxos Visuais

### Fluxo Principal do Usu√°rio

```mermaid
flowchart TD
    A[Usu√°rio acessa Dashboard] --> B{Autenticado?}
    B -->|N√£o| C[Login/MFA]
    B -->|Sim| D[Dashboard Home]
    C --> D
    
    D --> E[Interface Chat]
    E --> F[Digite/Fale Query]
    F --> G[Processamento LLM]
    
    G --> H{Tipo de Query?}
    H -->|Simples| I[Ollama Local]
    H -->|Complexa| J[Cloud LLM]
    H -->|H√≠brida| K[Local + Cloud]
    
    I --> L[Resposta <500ms]
    J --> M[Resposta <3s]
    K --> N[Resposta Otimizada]
    
    L --> O[Gerar Visualiza√ß√£o]
    M --> O
    N --> O
    
    O --> P[Exibir Resultado]
    P --> Q{Satisfeito?}
    Q -->|N√£o| R[Refinar Query]
    Q -->|Sim| S[Exportar/Compartilhar]
    R --> F
    S --> T[Finalizar Sess√£o]
```

### Fluxo de Processamento LLM

```mermaid
sequenceDiagram
    participant U as Usu√°rio
    participant F as Frontend
    participant G as LLM Gateway
    participant L as Ollama Local
    participant C as Cloud LLM
    participant DB as Database
    participant R as Redis Cache
    
    U->>F: Envia query
    F->>G: POST /api/llm/query
    
    G->>R: Verifica cache
    alt Cache Hit
        R-->>G: Resposta cached
        G-->>F: Retorna resultado
    else Cache Miss
        G->>G: Analisa complexidade
        
        alt Query Simples
            G->>L: Processa localmente
            L-->>G: Resposta
        else Query Complexa
            G->>C: Envia para cloud
            C-->>G: Resposta
        else Query H√≠brida
            par Processamento Paralelo
                G->>L: Contexto local
                G->>C: An√°lise complexa
            end
            L-->>G: Contexto
            C-->>G: Insights
            G->>G: Combina resultados
        end
        
        G->>R: Salva no cache
        G->>DB: Salva hist√≥rico
        G-->>F: Resposta final
    end
    
    F->>F: Gera visualiza√ß√£o
    F-->>U: Exibe resultado
```

### Arquitetura de Decis√£o LLM

```mermaid
flowchart TD
    A[Query Input] --> B[An√°lise de Complexidade]
    
    B --> C{An√°lise de Tipo}
    C -->|Agrega√ß√£o Simples| D[Score: 1-3]
    C -->|Filtros B√°sicos| E[Score: 1-2]
    C -->|Compara√ß√µes| F[Score: 2-4]
    C -->|Previs√µes| G[Score: 4-5]
    C -->|An√°lise Multi-dimensional| H[Score: 4-5]
    
    D --> I{Score ‚â§ 2?}
    E --> I
    F --> I
    G --> I
    H --> I
    
    I -->|Sim| J[Ollama Local]
    I -->|N√£o| K{Score ‚â§ 4?}
    
    K -->|Sim| L[H√≠brido: Local + Cloud]
    K -->|N√£o| M[Cloud LLM Only]
    
    J --> N[Cache Sem√¢ntico]
    L --> N
    M --> N
    
    N --> O[Resposta Final]
```

---

## ‚úÖ Crit√©rios de Aceita√ß√£o por Funcionalidade

### Feature 1: Interface Conversacional
#### Crit√©rios de Aceita√ß√£o
- [ ] **AC1.1**: Sistema processa queries em portugu√™s brasileiro
- [ ] **AC1.2**: Interface suporta entrada por texto e voz
- [ ] **AC1.3**: Hist√≥rico de conversas mantido por sess√£o
- [ ] **AC1.4**: Sugest√µes contextuais aparecem durante digita√ß√£o
- [ ] **AC1.5**: Tempo de resposta <500ms para queries locais
- [ ] **AC1.6**: Fallback gracioso quando LLM local falha
- [ ] **AC1.7**: M√°ximo 3 tentativas de retry em caso de erro

#### Cen√°rios de Teste
```gherkin
Cen√°rio: Query simples de m√©tricas
  Dado que o usu√°rio est√° logado no dashboard
  Quando ele digita "Quantas horas trabalhamos hoje?"
  Ent√£o o sistema deve:
    - Processar via Ollama local
    - Retornar resposta em <500ms
    - Exibir gr√°fico apropriado
    - Salvar no hist√≥rico

Cen√°rio: Query por voz
  Dado que o usu√°rio ativou o microfone
  Quando ele fala "Mostre a produtividade da equipe"
  Ent√£o o sistema deve:
    - Converter voz para texto
    - Processar a query normalmente
    - Confirmar entendimento antes de executar
```

### Feature 2: Processamento H√≠brido LLM
#### Crit√©rios de Aceita√ß√£o
- [ ] **AC2.1**: Router decide automaticamente entre local/cloud/h√≠brido
- [ ] **AC2.2**: 70%+ das queries processadas localmente
- [ ] **AC2.3**: Fallback para cloud quando local falha
- [ ] **AC2.4**: Custo por query <$0.01 em m√©dia
- [ ] **AC2.5**: Cache sem√¢ntico com 85%+ hit rate
- [ ] **AC2.6**: Logs detalhados de decis√µes de roteamento

#### Cen√°rios de Teste
```gherkin
Cen√°rio: Query complexa requer cloud
  Dado uma query "Preveja quando terminaremos o sprint baseado no ritmo atual"
  Quando o sistema analisa a complexidade
  Ent√£o deve:
    - Classificar como complexidade alta (score 4-5)
    - Rotear para cloud LLM
    - Registrar decis√£o nos logs
    - Processar em <3s

Cen√°rio: Economia de custos
  Dado 100 queries em um dia
  Quando analisamos o roteamento
  Ent√£o:
    - ‚â•70 queries processadas localmente (custo $0)
    - ‚â§30 queries enviadas para cloud
    - Custo total <$0.50 por dia
```

### Feature 3: Visualiza√ß√µes Autom√°ticas
#### Crit√©rios de Aceita√ß√£o
- [ ] **AC3.1**: IA escolhe tipo de gr√°fico baseado no contexto
- [ ] **AC3.2**: Suporte para 8+ tipos de visualiza√ß√£o (bar, line, pie, scatter, etc.)
- [ ] **AC3.3**: Gr√°ficos responsivos em desktop e mobile
- [ ] **AC3.4**: Op√ß√£o de exportar em PNG, PDF, SVG
- [ ] **AC3.5**: Drill-down interativo nos gr√°ficos
- [ ] **AC3.6**: Atualiza√ß√£o em tempo real via WebSocket

### Feature 4: Sistema de Cache Sem√¢ntico
#### Crit√©rios de Aceita√ß√£o
- [ ] **AC4.1**: Queries similares retornam resultado cached
- [ ] **AC4.2**: Similaridade calculada via embeddings
- [ ] **AC4.3**: TTL configur√°vel por tipo de query
- [ ] **AC4.4**: Cache invalidado quando dados mudam
- [ ] **AC4.5**: M√©tricas de cache hit/miss dispon√≠veis
- [ ] **AC4.6**: Limpeza autom√°tica de cache antigo

---

## üß™ Estrat√©gia de Testes

### Pir√¢mide de Testes
```
        /\
       /  \
      / E2E \ (10%)
     /______\
    /        \
   /Integration\ (20%)
  /_____________\
 /               \
/   Unit Tests    \ (70%)
\________________/
```

### Tipos de Teste

#### 1. Testes Unit√°rios (70%)
```typescript
// Exemplo: Teste do LLM Router
describe('LLMRouter', () => {
  describe('analyzeComplexity', () => {
    it('should classify simple queries as local', () => {
      const query = "Quantas horas trabalhamos hoje?";
      const complexity = router.analyzeComplexity(query);
      expect(complexity.score).toBeLessThan(3);
      expect(complexity.route).toBe('local');
    });
    
    it('should classify predictions as cloud', () => {
      const query = "Quando vamos terminar o projeto?";
      const complexity = router.analyzeComplexity(query);
      expect(complexity.score).toBeGreaterThan(3);
      expect(complexity.route).toBe('cloud');
    });
  });
});
```

#### 2. Testes de Integra√ß√£o (20%)
```typescript
describe('LLM Integration', () => {
  it('should process hybrid query correctly', async () => {
    const query = "Compare produtividade da equipe com m√™s passado";
    const response = await llmService.processQuery(query);
    
    expect(response.processedBy).toBe('hybrid');
    expect(response.visualization).toBeDefined();
    expect(response.responseTime).toBeLessThan(3000);
  });
});
```

#### 3. Testes E2E (10%)
```typescript
// Cypress E2E
describe('Dashboard Flow', () => {
  it('should complete full user journey', () => {
    cy.login();
    cy.visit('/dashboard');
    cy.get('[data-cy=chat-input]').type('M√©tricas de hoje');
    cy.get('[data-cy=send-button]').click();
    cy.get('[data-cy=chart-container]').should('be.visible');
    cy.get('[data-cy=response-text]').should('contain', 'horas');
  });
});
```

### Testes de Performance
```yaml
Load Testing:
  Tool: Artillery.js
  Scenarios:
    - name: "LLM Query Load"
      weight: 70
      flow:
        - post:
            url: "/api/llm/query"
            json:
              query: "{{ $randomString() }}"
    
    - name: "Dashboard Metrics"
      weight: 30
      flow:
        - get:
            url: "/api/dashboard/metrics"
  
  Target:
    duration: 300
    arrivalRate: 10
    maxVusers: 100
  
  Assertions:
    - http.response_time.p95: 3000
    - http.response_time.p50: 500
    - http.codes.200: 95%
```

### Testes de LLM Espec√≠ficos
```python
# Python - Teste de qualidade LLM
def test_llm_accuracy():
    test_cases = [
        {
            "query": "Quantas horas trabalhamos esta semana?",
            "expected_type": "aggregation",
            "expected_chart": "bar"
        },
        {
            "query": "Compare Jo√£o e Maria",
            "expected_type": "comparison",
            "expected_chart": "comparison_bar"
        }
    ]
    
    for case in test_cases:
        response = llm_service.process(case["query"])
        assert response.type == case["expected_type"]
        assert response.visualization.type == case["expected_chart"]
        assert response.hallucination_score < 0.1
```

---

## üë• Stakeholders

### Stakeholder Map
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 STAKEHOLDERS MAP                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Grupo       ‚îÇ   Papel     ‚îÇ   Interesse          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Sponsors      ‚îÇ C-Level     ‚îÇ ROI, Produtividade   ‚îÇ
‚îÇ Users         ‚îÇ Managers    ‚îÇ Insights, Facilidade ‚îÇ
‚îÇ Developers    ‚îÇ Time Dev    ‚îÇ Tracking, Fair Pay   ‚îÇ
‚îÇ Operations    ‚îÇ DevOps      ‚îÇ Estabilidade, Custos ‚îÇ
‚îÇ Security      ‚îÇ InfoSec     ‚îÇ Compliance, Privacy  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Comunica√ß√£o
- **Weekly Status**: Toda segunda-feira via Slack
- **Sprint Reviews**: Bi-semanais com demos
- **Executive Reports**: Mensais com KPIs
- **User Feedback**: Canal dedicado no Discord

---

## üèóÔ∏è Arquitetura T√©cnica

### Vis√£o Geral - Arquitetura H√≠brida
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              FlowForge Dashboard                     ‚îÇ
‚îÇ                Hybrid Architecture                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Vue 3   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Node.js  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   LLM    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Frontend ‚îÇ     ‚îÇ Backend  ‚îÇ     ‚îÇ Gateway  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ       ‚ñ≤                ‚ñ≤                 ‚ñ≤          ‚îÇ
‚îÇ       ‚îÇ                ‚îÇ                 ‚îÇ          ‚îÇ
‚îÇ       ‚ñº                ‚ñº                 ‚ñº          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇWebSocket ‚îÇ     ‚îÇPostgreSQL‚îÇ     ‚îÇ  Ollama  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇReal-time ‚îÇ     ‚îÇ Database ‚îÇ     ‚îÇ  (Local) ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                        ‚ñ≤                 ‚ñ≤          ‚îÇ
‚îÇ                        ‚îÇ                 ‚îÇ          ‚îÇ
‚îÇ                        ‚ñº                 ‚ñº          ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                   ‚îÇ  Redis   ‚îÇ     ‚îÇCloud LLM ‚îÇ   ‚îÇ
‚îÇ                   ‚îÇ  Cache   ‚îÇ     ‚îÇ (GPT-4)  ‚îÇ   ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stack Tecnol√≥gico

#### Frontend
- **Framework**: Vue 3.5 + TypeScript 5.6
- **Build Tool**: Vite 5.4
- **UI Library**: PrimeVue 4.0
- **Charts**: Chart.js 4.4 + Apache ECharts 5.5
- **State**: Pinia 2.2
- **Real-time**: Socket.io-client 4.8

#### Backend
- **Runtime**: Node.js 22 LTS
- **Framework**: Express 4.21 + TypeScript
- **Database**: PostgreSQL 16 + Prisma 6.0
- **Cache**: Redis 7.4
- **Queue**: Bull 4.16
- **Auth**: JWT + Passport.js

#### LLM Integration
- **Local**: Ollama 0.5 (Llama 3.2, Mistral)
- **Cloud**: OpenAI GPT-4, Claude 3, Gemini
- **Orchestration**: LangChain.js 0.3
- **Vector Store**: ChromaDB
- **Embeddings**: text-embedding-3-small

### Componentes Principais

1. **Chat Interface**: Componente conversacional com hist√≥rico contextual
2. **LLM Gateway**: Router inteligente para sele√ß√£o local vs cloud
3. **Query Processor**: Parser de linguagem natural e gerador de visualiza√ß√µes
4. **Cache System**: Multi-camada (memory, Redis, CDN)
5. **Real-time Engine**: WebSocket para atualiza√ß√µes ao vivo
6. **Analytics Engine**: Agrega√ß√µes e c√°lculos de m√©tricas

---

## üí¨ Funcionalidades com LLM

### Interface Conversacional

#### Exemplos de Intera√ß√£o
```
User: "Quantas horas trabalhamos esta semana?"
LLM: [Gr√°fico de barras] + "48 horas totais, m√©dia de 9.6h/dia"

User: "Compare produtividade entre Jo√£o e Maria"
LLM: [Gr√°fico comparativo] + "Jo√£o: 12 tickets, Maria: 8 tickets"

User: "Identifique gargalos no desenvolvimento"
LLM: [Timeline] + "3 gargalos: code review (2x tempo), 
      5 tickets parados, deploy manual (15% do tempo)"

User: "Preveja quando terminaremos o sprint"
LLM: [Proje√ß√£o] + "85% chance de conclus√£o at√© sexta-feira"
```

### Capacidades do Sistema

#### Processamento Local (Ollama - Custo Zero)
- Queries simples e diretas
- Agrega√ß√µes b√°sicas
- Filtros por data/pessoa
- Visualiza√ß√µes padr√£o
- Tempo de resposta: <500ms

#### Processamento Cloud (GPT-4/Claude - Premium)
- An√°lises complexas multi-dimensionais
- Previs√µes e proje√ß√µes
- Detec√ß√£o de anomalias
- Recomenda√ß√µes estrat√©gicas
- Tempo de resposta: 1-3s

#### Processamento H√≠brido (Otimizado)
- Local pr√©-processa e extrai contexto
- Cloud realiza an√°lise profunda
- Local p√≥s-processa e formata
- Melhor custo-benef√≠cio

### Features Especiais

1. **Voice-to-Query**: Fale com o dashboard em portugu√™s
2. **Auto-Visualiza√ß√£o**: IA escolhe melhor tipo de gr√°fico
3. **Insights Proativos**: Alertas autom√°ticos de anomalias
4. **Export Inteligente**: Relat√≥rios formatados automaticamente
5. **Multi-LLM Support**: Fallback entre providers
6. **Cache Sem√¢ntico**: Queries similares usam cache

---

## üîå Especifica√ß√µes de API

### RESTful Endpoints

```yaml
Dashboard API:
  GET /api/dashboard/metrics
    - Description: M√©tricas gerais do dashboard
    - Auth: Bearer token
    - Response: MetricsResponse
  
  GET /api/dashboard/sessions
    - Description: Sess√µes de trabalho ativas
    - Auth: Bearer token
    - Response: SessionsResponse

LLM Gateway:
  POST /api/llm/query
    - Description: Processar query em linguagem natural
    - Body: { query: string, context?: object }
    - Response: { answer: string, visualization?: Chart }
  
  GET /api/llm/suggestions
    - Description: Sugest√µes contextuais
    - Response: string[]

WebSocket Events:
  connect: Estabelecer conex√£o
  metrics.update: Atualiza√ß√£o de m√©tricas
  session.start: Nova sess√£o iniciada
  session.end: Sess√£o finalizada
  llm.response: Resposta do LLM
```

### GraphQL Schema

```graphql
type Query {
  dashboard: Dashboard!
  sessions(filter: SessionFilter): [Session!]!
  metrics(range: DateRange!): Metrics!
  llmQuery(input: String!): LLMResponse!
}

type Mutation {
  startSession(taskId: ID!): Session!
  endSession(sessionId: ID!): Session!
  sendLLMQuery(query: String!): LLMResponse!
}

type Subscription {
  metricsUpdate: Metrics!
  sessionUpdate: Session!
  llmStreaming(queryId: ID!): LLMStreamChunk!
}
```

---

## üóÑÔ∏è Modelagem de Dados

### Esquema Principal (PostgreSQL)

```sql
-- Tabela de Queries LLM
CREATE TABLE llm_queries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id),
    query_text TEXT NOT NULL,
    query_embedding vector(1536),
    response_text TEXT,
    visualization_spec JSONB,
    provider VARCHAR(50), -- 'local', 'openai', 'anthropic'
    model_used VARCHAR(100),
    tokens_used INTEGER,
    cost_cents INTEGER,
    response_time_ms INTEGER,
    cache_hit BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Tabela de M√©tricas
CREATE TABLE dashboard_metrics (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    project_id UUID REFERENCES projects(id),
    metric_type VARCHAR(50),
    metric_value NUMERIC,
    metadata JSONB,
    calculated_at TIMESTAMPTZ DEFAULT NOW()
);

-- √çndices para Performance
CREATE INDEX idx_llm_queries_user_created 
    ON llm_queries(user_id, created_at DESC);
CREATE INDEX idx_llm_queries_embedding 
    ON llm_queries USING ivfflat (query_embedding vector_cosine_ops);
CREATE INDEX idx_metrics_project_type 
    ON dashboard_metrics(project_id, metric_type);
```

### Cache Structure (Redis)

```javascript
// Cache Keys Pattern
{
  "dashboard:metrics:{projectId}": "2h TTL",
  "llm:query:{hash}": "24h TTL",
  "session:active:{userId}": "30min TTL",
  "suggestions:{context}": "1h TTL"
}
```

### Vector Store (ChromaDB)

```python
# Collections
collections = {
    "queries": {  # Historical queries for similarity
        "embedding_function": "text-embedding-3-small",
        "metadata": ["user_id", "timestamp", "cost"]
    },
    "documentation": {  # FlowForge docs for RAG
        "embedding_function": "text-embedding-3-small",
        "metadata": ["type", "version", "source"]
    }
}
```

---

## üìä Plano de Implementa√ß√£o

### Roadmap de 3 Meses

```mermaid
gantt
    title FlowForge Dashboard LLM - Roadmap
    dateFormat YYYY-MM-DD
    
    section M√™s 1 - MVP
    Setup Infraestrutura        :2025-01-01, 3d
    Frontend Base               :3d
    Backend Core                :4d
    LLM Integration B√°sica      :4d
    Testes e Ajustes           :2d
    Deploy Beta                :1d
    
    section M√™s 2 - Expans√£o
    RAG Implementation         :7d
    Cache Sem√¢ntico           :5d
    Ollama Local Setup        :5d
    Voice Interface           :3d
    
    section M√™s 3 - Enterprise
    Fine-tuning Prep          :5d
    Model Training            :7d
    Advanced Analytics        :8d
    Production Deploy         :2d
```

### Milestones e Tarefas

#### Milestone 1: MVP (2 semanas)
- [ ] TASK-001: Setup Vue 3 + TypeScript (0.2h)
- [ ] TASK-002: Configurar PrimeVue e tema (0.2h)
- [ ] TASK-003: Backend Express scaffolding (0.2h)
- [ ] TASK-004: PostgreSQL + Prisma setup (0.3h)
- [ ] TASK-005: Integra√ß√£o GPT-4 b√°sica (0.3h)
- [ ] TASK-006: Chat interface simples (0.3h)
- [ ] TASK-007: 5 queries pr√©-definidas (0.3h)
- [ ] TASK-008: Deploy em staging (0.2h)

#### Milestone 2: H√≠brido (1 m√™s)
- [ ] TASK-009: Instalar Ollama server (0.3h)
- [ ] TASK-010: Router inteligente LLM (0.3h)
- [ ] TASK-011: ChromaDB vector store (0.3h)
- [ ] TASK-012: RAG pipeline (0.3h)
- [ ] TASK-013: Cache sem√¢ntico Redis (0.2h)
- [ ] TASK-014: Voice-to-text PT-BR (0.3h)
- [ ] TASK-015: Visualiza√ß√µes din√¢micas (0.3h)
- [ ] TASK-016: Fallback system (0.2h)

#### Milestone 3: Production (2-3 meses)
- [ ] TASK-017: Dataset preparation (0.3h)
- [ ] TASK-018: Fine-tuning GPT-3.5 (0.3h)
- [ ] TASK-019: A/B testing framework (0.3h)
- [ ] TASK-020: Advanced analytics (0.3h)
- [ ] TASK-021: Anomaly detection (0.3h)
- [ ] TASK-022: Cost optimization (0.2h)
- [ ] TASK-023: Security hardening (0.3h)
- [ ] TASK-024: Production deploy (0.2h)

---

## üìã Gest√£o de Mudan√ßa e Treinamento

### Estrat√©gia de Ado√ß√£o

#### Fase 1: Pioneiros (Semana 1-2)
**P√∫blico**: 2-3 early adopters t√©cnicos
**Objetivo**: Validar funcionalidades b√°sicas e coletar feedback inicial
**Atividades**:
- Workshop de 2h sobre funcionalidades
- Uso supervisionado por 1 semana
- Sess√µes de feedback di√°rias
- Ajustes baseados na experi√™ncia

#### Fase 2: Grupo Piloto (Semana 3-6)
**P√∫blico**: 30% da equipe (managers e leads)
**Objetivo**: Testar em cen√°rios reais e refinar UX
**Atividades**:
- Treinamento de 1h para novos usu√°rios
- Documenta√ß√£o de casos de uso
- Suporte dedicado via Slack
- M√©tricas de ado√ß√£o semanais

#### Fase 3: Rollout Completo (Semana 7-12)
**P√∫blico**: 100% da organiza√ß√£o
**Objetivo**: Ado√ß√£o completa e autonomia
**Atividades**:
- Sess√µes de treinamento em grupo (30min)
- V√≠deos tutoriais auto-explicativos
- FAQ baseado em feedback real
- Champions internos para suporte

### Material de Treinamento

#### Tutorial Interativo (In-App)
```typescript
// Exemplo de tutorial guiado
const tutorialSteps = [
  {
    target: '.chat-input',
    title: 'Digite sua pergunta',
    content: 'Fa√ßa perguntas em portugu√™s natural, como "Quantas horas trabalhei hoje?"',
    position: 'bottom'
  },
  {
    target: '.voice-button',
    title: 'Use sua voz',
    content: 'Clique aqui para falar diretamente com o dashboard',
    position: 'left'
  },
  {
    target: '.chart-container',
    title: 'Visualiza√ß√µes autom√°ticas',
    content: 'O sistema gera gr√°ficos baseados na sua pergunta',
    position: 'top'
  }
];
```

#### V√≠deos de Treinamento
1. **"Primeiros Passos"** (5min): Login, navega√ß√£o b√°sica, primeira query
2. **"Queries Avan√ßadas"** (8min): Compara√ß√µes, filtros, previs√µes
3. **"Interface de Voz"** (3min): Como usar comandos de voz efetivamente
4. **"Exportando Dados"** (4min): Salvando gr√°ficos e relat√≥rios

#### Guia de Refer√™ncia R√°pida
```markdown
# Quick Reference - Perguntas Comuns

## M√©tricas B√°sicas
- "Horas trabalhadas hoje/semana/m√™s"
- "Quantos tickets fechamos?"
- "Qual o status do sprint atual?"

## Compara√ß√µes
- "Compare [pessoa A] com [pessoa B]"
- "Esta semana vs semana passada"
- "Performance por projeto"

## Previs√µes
- "Quando vamos terminar o sprint?"
- "Vamos cumprir o prazo?"
- "Quantos tickets podemos fazer?"

## Troubleshooting
- Se n√£o entender: Seja mais espec√≠fico
- Erro de dados: Verifique se sessions est√£o rodando
- Resposta lenta: Query complexa foi para cloud (normal)
```

### Plano de Comunica√ß√£o

#### Pr√©-Lan√ßamento (2 semanas antes)
- **Email executivo**: An√∫ncio oficial do projeto
- **All-hands meeting**: Apresenta√ß√£o de 15min sobre benef√≠cios
- **Slack channel**: Cria√ß√£o de #flowforge-dashboard-beta

#### Durante Rollout (Semanas 1-12)
- **Weekly updates**: Status de ado√ß√£o e novidades
- **Success stories**: Cases de uso que geraram valor
- **Feature highlights**: Showcases de funcionalidades

#### P√≥s-Lan√ßamento (Cont√≠nuo)
- **Monthly metrics**: KPIs de ado√ß√£o e satisfa√ß√£o
- **Feature requests**: Canal para sugest√µes da comunidade
- **Best practices**: Compartilhamento de queries √∫teis

### M√©tricas de Ado√ß√£o

```yaml
Ado√ß√£o por Fase:
  Fase 1 (Pioneiros):
    - Usu√°rios ativos: 100%
    - Queries por dia: >10
    - NPS: >7
  
  Fase 2 (Piloto):
    - Usu√°rios ativos: >80%
    - Queries por usu√°rio/dia: >3
    - Tickets de suporte: <2/semana
  
  Fase 3 (Rollout):
    - Usu√°rios ativos: >90%
    - Substitui√ß√£o de relat√≥rios manuais: >50%
    - ROI demonstrado: 3 meses
```

---

## üí∞ An√°lise de Custos

### Custos de Desenvolvimento
| Item | Horas | Custo/Hora | Total |
|------|-------|------------|-------|
| **Frontend** | 40h | $150 | $6,000 |
| **Backend** | 60h | $150 | $9,000 |
| **LLM Integration** | 40h | $200 | $8,000 |
| **Testing** | 20h | $120 | $2,400 |
| **DevOps** | 20h | $180 | $3,600 |
| **Total** | 180h | - | **$29,000** |

### Custos Operacionais (Mensal)
| Componente | Uso Baixo | Uso M√©dio | Uso Alto |
|------------|-----------|-----------|----------|
| **Cloud LLM (30%)** | $30 | $100 | $300 |
| **Infraestrutura** | $100 | $200 | $500 |
| **Ollama Server** | $50 | $50 | $100 |
| **Total Mensal** | **$180** | **$350** | **$900** |

### ROI Esperado
- **Economia em Relat√≥rios**: 10h/semana √ó $100/h = $4,000/m√™s
- **Redu√ß√£o de Custos LLM**: 60-70% vs cloud-only = $200-500/m√™s
- **Aumento de Produtividade**: 20% = ~$8,000/m√™s valor agregado
- **Payback**: 2-3 meses

---

## üîí Seguran√ßa e Compliance

### Medidas de Seguran√ßa
1. **Autentica√ß√£o**: JWT com refresh tokens, MFA opcional
2. **Autoriza√ß√£o**: RBAC com pol√≠ticas granulares
3. **Criptografia**: TLS 1.3 em tr√¢nsito, AES-256 em repouso
4. **Sanitiza√ß√£o**: Input validation, output encoding
5. **Rate Limiting**: Por endpoint e por usu√°rio
6. **Audit Trail**: Log completo de todas a√ß√µes

### Privacidade de Dados
- **LGPD/GDPR Compliance**: Direito ao esquecimento, portabilidade
- **Data Minimization**: Apenas dados necess√°rios
- **Anonymization**: PII removido antes do LLM
- **Local Processing**: Dados sens√≠veis nunca saem do servidor

### LLM Security
- **Prompt Injection Prevention**: Input sanitization
- **Token Limits**: M√°ximo de tokens por request
- **Cost Thresholds**: Alertas de gastos anormais
- **Output Validation**: Verifica√ß√£o de respostas

---

## ‚ö†Ô∏è Riscos e Mitiga√ß√µes

### Riscos T√©cnicos
| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Lat√™ncia do LLM** | M√©dia | Alto | Cache agressivo, timeouts |
| **Custos de API** | Alta | M√©dio | H√≠brido local/cloud |
| **Falha do Ollama** | Baixa | M√©dio | Fallback para cloud |
| **Volume de dados** | M√©dia | M√©dio | Pagina√ß√£o, lazy loading |

### Riscos de Neg√≥cio
| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Baixa ado√ß√£o** | M√©dia | Alto | Training, UX simples |
| **ROI n√£o atingido** | Baixa | Alto | M√©tricas claras, itera√ß√£o |
| **Compliance issues** | Baixa | Alto | Audit regular, LGPD |

---

## üìà M√©tricas de Sucesso

### Technical Metrics
- **Response Time**: p95 < 500ms (local), < 3s (cloud)
- **Availability**: 99.9% uptime
- **Error Rate**: < 0.1%
- **Cache Hit Ratio**: > 85%
- **Query Success Rate**: > 95%

### Business Metrics
- **User Adoption**: 100% em 3 meses
- **Time Saved**: 10h/semana em relat√≥rios
- **Cost Reduction**: 60% em APIs LLM
- **User Satisfaction**: NPS > 50
- **ROI**: Positivo em 3 meses

### LLM Specific Metrics
- **Query Accuracy**: > 90%
- **Hallucination Rate**: < 5%
- **Local Processing**: > 70% queries
- **Average Cost/Query**: < $0.01
- **Context Relevance**: > 85%

---

## üìÑ Ap√™ndice: Technical Decision Records (TDRs)

### TDR-001: Arquitetura H√≠brida LLM

**Data**: 2025-09-12  
**Status**: Approved  
**Contexto**: Precisamos balancear custo e qualidade no processamento de queries

**Decis√£o**: Implementar arquitetura h√≠brida com Ollama local + Cloud LLM

**Op√ß√µes Consideradas**:
1. **Cloud-only** (GPT-4 para tudo)
   - Pros: Qualidade m√°xima, simplicidade
   - Cons: Custo alto ($500-2000/m√™s)

2. **Local-only** (Ollama apenas)
   - Pros: Custo zero, privacidade
   - Cons: Limita√ß√µes em an√°lises complexas

3. **H√≠brida** (Local + Cloud inteligente) ‚úÖ
   - Pros: 60-70% economia, qualidade mantida
   - Cons: Complexidade arquitetural

**Consequ√™ncias**:
- Router inteligente necess√°rio
- Sistema de fallback requerido
- Monitoramento de custos cr√≠tico
- Potencial economia de $300-1500/m√™s

### TDR-002: Frontend Framework Selection

**Data**: 2025-09-12  
**Status**: Approved  
**Contexto**: Escolha do framework para interface do dashboard

**Decis√£o**: Vue 3 + TypeScript + PrimeVue

**Op√ß√µes Consideradas**:
1. **React + TypeScript**
   - Pros: Ecossistema grande, skills existentes
   - Cons: Overhead, complexidade

2. **Vue 3 + TypeScript** ‚úÖ
   - Pros: Simplicidade, performance, Composition API
   - Cons: Menor ecosistema que React

3. **Svelte + TypeScript**
   - Pros: Performance m√°xima, simplicidade
   - Cons: Ecosystem limitado, skills gap

**Consequ√™ncias**:
- Curva de aprendizado m√≠nima
- PrimeVue fornece componentes UI prontos
- TypeScript garante type safety
- Desenvolvimento mais r√°pido

### TDR-003: Vector Database Selection

**Data**: 2025-09-12  
**Status**: Approved  
**Contexto**: Cache sem√¢ntico requer busca por similaridade

**Decis√£o**: ChromaDB para vector store

**Op√ß√µes Consideradas**:
1. **Pinecone**
   - Pros: Managed service, escalabilidade
   - Cons: Custo, vendor lock-in

2. **ChromaDB** ‚úÖ
   - Pros: Open source, local, Python integra√ß√£o
   - Cons: Menos features enterprise

3. **Weaviate**
   - Pros: GraphQL, features avan√ßadas
   - Cons: Complexidade, overhead

**Consequ√™ncias**:
- Self-hosted reduz custos
- Integra√ß√£o com pipeline Python
- Controle total sobre dados
- Poss√≠vel migra√ß√£o futura para managed

### TDR-004: Cache Strategy

**Data**: 2025-09-12  
**Status**: Approved  
**Contexto**: Otimiza√ß√£o de performance e custos LLM

**Decis√£o**: Multi-layer cache (Memory + Redis + Semantic)

**Op√ß√µes Consideradas**:
1. **Redis simples**
   - Pros: Simplicidade
   - Cons: Miss em queries similares

2. **Cache sem√¢ntico only**
   - Pros: Inteligente
   - Cons: Overhead computacional

3. **Multi-layer** ‚úÖ
   - Pros: Melhor hit rate, performance
   - Cons: Complexidade gerencial

**Consequ√™ncias**:
- L1: Memory cache (100ms)
- L2: Redis cache (10ms)
- L3: Semantic cache (ChromaDB)
- Target: 85%+ hit rate

---

## üîÑ Controle de Vers√£o e Manuten√ß√£o

### Versionamento do Documento

| Vers√£o | Data | Autor | Mudan√ßas |
|--------|------|-------|----------|
| 1.0.0 | 2025-09-12 | FlowForge Maestro | Vers√£o inicial |
| 2.0.0 | 2025-09-12 | FFT-Documentation | Enhanced com todas se√ß√µes |

### Processo de Revis√£o

#### Revis√µes Obrigat√≥rias
- **Semanal**: Durante desenvolvimento ativo
- **Mensal**: Durante opera√ß√£o normal
- **Ad-hoc**: Quando mudan√ßas significativas ocorrem

#### Crit√©rios de Atualiza√ß√£o
```yaml
Triggers para atualiza√ß√£o:
  - Mudan√ßa na arquitetura: Major version bump
  - Novos features: Minor version bump
  - Corre√ß√µes/clarifica√ß√µes: Patch version bump
  - Feedback de stakeholders: Review necess√°ria
  - Mudan√ßas regulat√≥rias: Immediate update
```

#### Processo de Approval
1. **Autor** cria draft das mudan√ßas
2. **Tech Lead** revisa aspectos t√©cnicos
3. **Product Owner** revisa requisitos de neg√≥cio
4. **Security** revisa mudan√ßas de seguran√ßa (se aplic√°vel)
5. **Stakeholders** aprova√ß√£o final
6. **Publica√ß√£o** e comunica√ß√£o das mudan√ßas

### Manuten√ß√£o da Documenta√ß√£o

#### Responsabilidades
- **Product Owner**: Mant√©m requisitos de neg√≥cio atualizados
- **Tech Lead**: Garante precis√£o t√©cnica
- **Documentation Lead**: Coordena processo de atualiza√ß√£o
- **Team Members**: Reportam inconsist√™ncias/gaps

#### M√©tricas de Qualidade
```yaml
Quality Gates:
  - Links funcionais: 100%
  - Se√ß√µes desatualizadas: 0
  - Feedback n√£o endere√ßado: <7 dias
  - Reviews em atraso: 0
  - Stakeholder NPS: >4.0/5.0
```

---

## üöÄ Pr√≥ximos Passos

### Imediato (Semana 1)
1. ‚úÖ Aprovar PRD e arquitetura
2. üîÑ Criar issues no GitHub (#468-#494)
3. üìã Setup ambiente de desenvolvimento
4. üèóÔ∏è Iniciar implementa√ß√£o do MVP

### Curto Prazo (M√™s 1)
1. üéØ MVP funcional com queries b√°sicas
2. üß™ Testes com usu√°rios beta
3. üìä Coletar m√©tricas iniciais
4. üîÑ Itera√ß√£o baseada em feedback

### M√©dio Prazo (Meses 2-3)
1. ü§ñ Implementar processamento h√≠brido
2. üé§ Adicionar interface de voz
3. üìà Fine-tuning com dados reais
4. üöÄ Deploy em produ√ß√£o

---

## üìû Contatos

### Time Core
- **Product Owner**: [Alex Cruz]
- **Tech Lead**: [TBD]
- **LLM Specialist**: [TBD]
- **DevOps Lead**: [TBD]

### Canais de Comunica√ß√£o
- **Slack**: #flowforge-dashboard
- **GitHub**: github.com/JustCode-CruzAlex/FlowForge
- **Documentation**: /documentation/2.0/dashboard/

---

## üìé Anexos

### Documentos Relacionados
1. [Arquitetura T√©cnica Detalhada](./architecture/technical_spec.md)
2. [API Specification](./api/FLOWFORGE_DASHBOARD_API_SPEC.md)
3. [Database Schema](./database/schema/)
4. [Test Plan](./testing/test_plan.md)
5. [Security Assessment](./security/assessment.md)

### Refer√™ncias
- [FlowForge Documentation](https://flowforge.io/docs)
- [Ollama Documentation](https://ollama.ai/docs)
- [LangChain.js Guide](https://js.langchain.com)
- [Vue 3 Best Practices](https://vuejs.org/guide)

---

**Documento gerado pelo FlowForge Maestro System**  
**Vers√£o**: 2.0.0  
**Data**: 2025-09-12  
**Status**: Aguardando Aprova√ß√£o

---

## üéØ Call to Action

**Para aprovar este PRD e iniciar o desenvolvimento:**

```bash
# Aprovar e criar issues
/flowforge:session:start dashboard-llm

# Ou revisar altera√ß√µes necess√°rias
# Informe quais ajustes s√£o necess√°rios
```

Este PRD foi criado atrav√©s da orquestra√ß√£o de m√∫ltiplos agentes especialistas FlowForge, garantindo completude t√©cnica e alinhamento com os objetivos de neg√≥cio.